apiVersion: ai.sap.com/v1alpha1
kind: ServingTemplate
metadata:
  name: wiproleakageprediction-infer
  annotations:
    scenarios.ai.sap.com/description: "This scenario predicts the water leakage based on the various parameters such as flow and pressure"
    scenarios.ai.sap.com/name: "wiproleakageprediction-sc"
    executables.ai.sap.com/description: "Inference executable for Water leakage predictions"
    executables.ai.sap.com/name: "wiproleakageprediction-infer-exec"
  labels:
    scenarios.ai.sap.com/id: "wiproleakageprediction"
    executables.ai.sap.com/id: "wiproleakageprediction"
    ai.sap.com/version: "1.0.0"
spec:
  inputs:
    parameters: []
    artifacts:
      - name: wiproleakageprediction-model
  template:
    apiVersion: "serving.kubeflow.org/v1beta1"
    metadata:
      annotations: |
        autoscaling.knative.dev/metric: concurrency
        autoscaling.knative.dev/target: 1
        autoscaling.knative.dev/targetBurstCapacity: 0
      labels: |
        ai.sap.com/resourcePlan: starter
    spec: |
      predictor:
        imagePullSecrets:
          - name: docker-registry-secret
        minReplicas: 1
        maxReplicas: 5
        containers:
        - name: kfserving-container
          image: "docker.io/hyperscalaruser/wiplp-serve:0.0.1"
          ports:
            - containerPort: 9001
              protocol: TCP
          env:
            - name: STORAGE_URI
              value: "{{inputs.artifacts.wiproleakageprediction-model}}"
